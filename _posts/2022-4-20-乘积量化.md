---
title:      乘积量化(Product Quantization, PQ)               # 标题 
date:       2022-04-06              # 时间
author:     vhwz                      # 作者
categories: [Algorithm, DeepLearning]
---


## 乘积量化PQ(Product Quantization)
乘积量化由论文[Product quantization for nearest neighbor search](https://lear.inrialpes.fr/pubs/2011/JDS11/jegou_searching_with_quantization.pdf)提出，用于降低向量的维度，从而在最近邻检索中减少运算量，加速运算

### 训练

步骤:

输入：训练集：n个D维的向量 input.shape = (n, D)

1.将向量切分为M段，每段长度D//M， 如果D不能被M整除，最后一段长度可以小于D//M， 结果得到M组 (n, D//M)的向量

2.对每组向量进行K-means聚类，设类别数为k，这样就得到了M个聚类器

### 测试

输入：

reference set n1个D维的向量 shape = (n1, D) 在这个数据集上查找

query set n2个D维的向量 shape = (n2, D) 要在reference set 中查找与query set相似的向量

步骤：

reference set 和 query set中向量做同样的处理

1.将向量切分为M段，每段长度D//M， 如果D不能被M整除，最后一段长度可以小于D//M， 结果得到M组

2.利用训练好的聚类器预测每组中向量的聚类标签， 用聚类标签代表这一向量，结果一组(n, D//M)的向量变为(n, 1)的向量

3.汇总M组，结果得到(n, M)的向量，这样就将D维向量压缩成了M维

压缩完成后，如何计算压缩后的向量之间的距离呢？我们不能直接使用L2距离，因为此时向量中元素是聚类标签

举例说明，假设向量维度D = 6，分组数M = 3, 聚类类别数k = 3

reference set中某一向量被压缩为 r = [0, 1, 2]

query set 中 某一向量被压缩为 q = [0, 0, 0]

此时可以使用聚类中心之间的距离之和作为 r, q 之间的距离 d(r, q)

假设 聚类类别0, 1之间的距离为5， 类别0, 2之间的距离为10, 相同类别之间的距离显然为0

则 d(r, q) = 0 + 5 + 10 = 15

显然，为了计算压缩后向量的距离，我们需要在训练结束时保存每组中每个类别的聚类中心。

为了在实际使用中加速计算，我们可以将各个组的聚类中心之间的距离预处理出来，使用时直接查询即可。

利用聚类中心之间的距离之和作为 r, q 之间的距离 d(r, q)，这种距离计算方法称为对称距离(SDC, symmetric distance computation)

还可以采用另一种距离计算方法非对称距离(ADC, asymmetric distance computation)
ADC只对reference set中的向量进行压缩， 而对query set 中的向量只分组而不进行压缩， 计算距离时
d(r, q) = sum(d(r第i组的聚类中心, q第i组向量)) where i = 1,..M, 我们同样可以预处理出q中各组向量与对应组的聚类中心的距离，使用时直接查询

乘积量化的实现如下， 实现中使用的距离为SDC，但在论文中，作者分析得出ADC的期望误差上界更小，因此推荐使用ADC
```python
import numpy as np
from sklearn.cluster import KMeans
from tqdm import tqdm

class PQ:
    def __init__(self, M, n_clusters):
        self.M = M
        self.n_clusters = n_clusters
        self.estimators = None
        self.dis_lookup = None
        
    def split(self, data):
        '''
        data: np.array(n, D)
        return List((n, D//M), (n, D//M))
        '''
        res = []
        n, D = data.shape
        L = D // self.M
        for i in range(self.M):
            res.append(data[:, i*L : (i+1)*L])   
        return res
    
    def kmeans(self, data):
        '''
        data: List(List(D//M), List(D//M), ...)
        '''
        estimators = [KMeans(n_clusters=self.n_clusters) for _ in range(self.M)]
        for i, est in tqdm(enumerate(estimators)):
            est.fit(data[i])
        return estimators
    
    def fit(self, data):
        '''
        data: np.array(n, D)
        '''
        data = self.split(data)
        self.estimators = self.kmeans(data)
        self.dis_lookup = []
        for est in self.estimators:
            dis = {}
            for i in range(self.n_clusters):
                for j in range(i, self.n_clusters):
                    dis[(i, j)] = dis[(j, i)] = self.distance(est.cluster_centers_[i], est.cluster_centers_[j])
            self.dis_lookup.append(dis)
    
    def predict(self, data):
        '''
        data: np.array(n, D)
        return np.array(n, M)
        '''
        data = self.split(data)
        ans = []
        for i, est in enumerate(self.estimators):
            ans.append(est.predict(data[i]))
        ans = np.array(ans)
        ans = ans.T
        return ans
    
    def distance(self, f1, f2):
        return np.mean((f1 - f2)**2)
    
    def distance_center(self, group, i, j):
        return self.dis_lookup[group][(i, j)]
    
    def distance_pqencode(self, f1, f2):
        dis = 0
        for group, (i, j) in enumerate(zip(f1, f2)):
            dis += self.distance_center(group, i, j)
        return dis
```
论文作者提供了数据集的[下载链接](http://corpus-texmex.irisa.fr/)， 我们可以在数据集上进行测试
```python
# read data
def ivecs_read(fname):
    a = np.fromfile(fname, dtype='int32')
    d = a[0]
    return a.reshape(-1, d + 1)[:, 1:].copy()

def fvecs_read(fname):
    return ivecs_read(fname).view('float32')

base = fvecs_read('/dataset/siftsmall/siftsmall_base.fvecs')
query = fvecs_read('/dataset/siftsmall/siftsmall_query.fvecs')
gt = ivecs_read('/dataset/siftsmall/siftsmall_groundtruth.ivecs')

pq = PQ(M = 8, n_clusters=256)
pq.fit(base) # train

base_feature = pq.predict(base)
features = pq.predict(query)

res = []
for i in tqdm(range(len(features))):
    r = []
    for j in range(len(base_feature)):
        r.append((pq.distance_pqencode(base_feature[j], features[i]), j))
    res.append(sorted(r))

ans = []
for r in res:
    t = [y[1] for y in r[:100]]
    ans.append(t)

recall = 0
total = 0
for i in range(100):
    for a in ans[i]:
        if a in gt[i]:
            recall += 1
        total += 1
print('recall:', recall/total)
```
经过测试，recall@100 =  0.6057 

也可以使用现成的库，例如faiss

```python
import faiss

m = 8                                 
n_bits = 8                          
pq = faiss.IndexPQ (128, m, n_bits)      
pq.train (train)                      
pq.add (ref)                        
D, I = pq.search (query, 100)         

correct = 0
total = 0
for i in tqdm(range(gt.shape[0])):
    for pred in I[i]:
        if pred in gt[i]:
            correct += 1
        total += 1
        
print(correct/total, correct, total)
```
经过测试，recall@100 =  0.6769 